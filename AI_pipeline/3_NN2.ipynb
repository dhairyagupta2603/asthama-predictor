{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n",
      "2.12.0\n",
      "GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten, Dropout, MaxPool1D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Accuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(pd.__version__)\n",
    "print(tf.__version__)\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/mfcc_data/grpd_samples'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = os.path.join('..', '..', 'data', 'mfcc_data', 'grpd_samples')\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aa': '../../data/mfcc_data/grpd_samples/aa',\n",
       " 'yy': '../../data/mfcc_data/grpd_samples/yy',\n",
       " 'ee': '../../data/mfcc_data/grpd_samples/ee',\n",
       " 'uu': '../../data/mfcc_data/grpd_samples/uu',\n",
       " 'oo': '../../data/mfcc_data/grpd_samples/oo'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonons = os.listdir(data_folder)\n",
    "\n",
    "data_path = {}\n",
    "for phonon in phonons:\n",
    "    data_path[phonon] = os.path.join(data_folder, phonon)\n",
    "\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for phonon, phonon_path in data_path.items():\n",
    "# for type_df in os.listdir(data_path['aa']):\n",
    "df_paths = os.path.join(data_path['aa'], 'train')\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for subject in os.listdir(df_paths):\n",
    "    df = pd.read_csv(os.path.join(df_paths, subject),  sep=',', index_col=False)\n",
    "\n",
    "    x = df.loc[:, df.columns != 'asthma_status'].to_numpy()\n",
    "    y = df.loc[:, df.columns == 'asthma_status'].to_numpy()[0]\n",
    "\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "\n",
    "X = np.stack(X, axis = 0)\n",
    "Y = np.stack(Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 400, 12)\n",
      "(117, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths = os.path.join(data_path['aa'], 'val')\n",
    "\n",
    "Xv = []\n",
    "Yv = []\n",
    "for subject in os.listdir(df_paths):\n",
    "    df = pd.read_csv(os.path.join(df_paths, subject),  sep=',', index_col=False)\n",
    "\n",
    "    x = df.loc[:, df.columns != 'asthma_status'].to_numpy()\n",
    "    y = df.loc[:, df.columns == 'asthma_status'].to_numpy()[0]\n",
    "\n",
    "    Xv.append(x)\n",
    "    Yv.append(y)\n",
    "\n",
    "Xv = np.stack(Xv, axis = 0)\n",
    "Yv = np.stack(Yv, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 400, 12)\n",
      "(34, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Xv.shape)\n",
    "print(Yv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paths = os.path.join(data_path['aa'], 'test')\n",
    "\n",
    "Xt = []\n",
    "Yt = []\n",
    "for subject in os.listdir(df_paths):\n",
    "    df = pd.read_csv(os.path.join(df_paths, subject),  sep=',', index_col=False)\n",
    "\n",
    "    x = df.loc[:, df.columns != 'asthma_status'].to_numpy()\n",
    "    y = df.loc[:, df.columns == 'asthma_status'].to_numpy()[0]\n",
    "\n",
    "    Xt.append(x)\n",
    "    Yt.append(y)\n",
    "\n",
    "Xt = np.stack(Xt, axis = 0)\n",
    "Yt = np.stack(Yt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 400, 12)\n",
      "(17, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Xt.shape)\n",
    "print(Yt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker_aa_o(hp):\n",
    "    model = keras.Sequential(name='Phonon_to_Asthama_NN')\n",
    "    model.add(keras.Input(shape=(400, 12)))\n",
    "\n",
    "    hp_ks = hp.Int(f'fs', min_value=5, max_value=20, step=5)\n",
    "    hp_pad = hp.Choice('padding', ['valid', 'same'])\n",
    "    \n",
    "    # conv1\n",
    "    model.add(Conv1D(\n",
    "        hp.Int(f'nf1', min_value=16, max_value=92, step=15),\n",
    "        kernel_size=hp_ks, padding=hp_pad, activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPool1D())\n",
    "\n",
    "    # conv2\n",
    "    model.add(Conv1D(\n",
    "        hp.Int(f'nf2', min_value=16, max_value=92, step=15),\n",
    "        kernel_size=hp_ks, padding=hp_pad, activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPool1D())\n",
    "    \n",
    "    # flatten\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # dense1\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # model.add(Dropout(0.10))\n",
    "\n",
    "    # dens2\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # model.add(Dropout(0.10))\n",
    "    \n",
    "    # output\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=BinaryCrossentropy(),\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=[BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "    return  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker_aa(hp):\n",
    "    model = keras.Sequential(name='Phonon_to_Asthama_NN')\n",
    "    model.add(keras.Input(shape=(419, 12)))\n",
    "    \n",
    "    for i in range(2):\n",
    "        model.add(Conv1D(\n",
    "            hp.Int(f'nfilters_{i}', min_value=128, max_value=512, step=64),\n",
    "            kernel_size=(hp.Int(f'fsize_{i}', min_value=5, max_value=20, step=5)),\n",
    "            padding='valid',\n",
    "            activation='relu'\n",
    "        ))\n",
    "        model.add(MaxPool1D())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    for i in range(1, hp.Int(\"num_layers_dense\", 2, 3)):\n",
    "        model.add(Dense(\n",
    "            hp.Int('layer1', min_value=128, max_value=512, step=64),\n",
    "            activation='relu'\n",
    "        ))\n",
    "        # model.add(Dropout(0.10))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=BinaryCrossentropy(),\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        metrics=[BinaryAccuracy()]\n",
    "    )\n",
    "\n",
    "    return  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Phonon_to_Asthama_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_2 (Conv1D)           (None, 396, 16)           976       \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 198, 16)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 194, 16)           1296      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 97, 16)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1552)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                99392     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,889\n",
      "Trainable params: 105,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner_aa3 = kt.Hyperband(\n",
    "    model_maker_aa_o,\n",
    "    objective='val_binary_accuracy',\n",
    "    max_epochs=40,\n",
    "    factor=3,\n",
    "    directory='tuned_models',\n",
    "    project_name='aa_s3'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_binary_accuracy', patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 65 Complete [00h 00m 07s]\n",
      "val_binary_accuracy: 0.6176470518112183\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.6176470518112183\n",
      "Total elapsed time: 00h 05m 26s\n",
      "\n",
      "Search: Running Trial #66\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "10                |20                |fs\n",
      "valid             |same              |padding\n",
      "31                |61                |nf1\n",
      "46                |16                |nf2\n",
      "160               |128               |layer1\n",
      "160               |128               |layer2\n",
      "5                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n",
      "Model: \"Phonon_to_Asthama_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 391, 31)           3751      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 195, 31)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 186, 46)           14306     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 93, 46)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4278)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 160)               684640    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 160)               25760     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 161       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 728,618\n",
      "Trainable params: 728,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "117/117 [==============================] - ETA: 0s - loss: 5.9327 - binary_accuracy: 0.6154"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuner_aa3\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m      2\u001b[0m     X, Y, \n\u001b[1;32m      3\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, \n\u001b[1;32m      4\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(Xv, Yv), \n\u001b[1;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \n\u001b[1;32m      6\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      7\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[stop_early]\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/tuners/hyperband.py:425\u001b[0m, in \u001b[0;36mHyperband.run_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/epochs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    424\u001b[0m     fit_kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mvalues[\u001b[39m\"\u001b[39m\u001b[39mtuner/initial_epoch\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 425\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/engine/tuner.py:214\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    213\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 214\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    216\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras_tuner/engine/hypermodel.py:144\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/engine/training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1716\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1717\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1728\u001b[0m     )\n\u001b[0;32m-> 1729\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1730\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1731\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1732\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1733\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1734\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1735\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1736\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1737\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1738\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1739\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1740\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1741\u001b[0m )\n\u001b[1;32m   1742\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1743\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1744\u001b[0m }\n\u001b[1;32m   1745\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/engine/training.py:2065\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2063\u001b[0m callbacks\u001b[39m.\u001b[39mon_test_begin()\n\u001b[1;32m   2064\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m-> 2065\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreset_metrics()\n\u001b[1;32m   2066\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m   2067\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/engine/training.py:2448\u001b[0m, in \u001b[0;36mModel.reset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resets the state of all the metrics in the model.\u001b[39;00m\n\u001b[1;32m   2430\u001b[0m \n\u001b[1;32m   2431\u001b[0m \u001b[39mExamples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2445\u001b[0m \n\u001b[1;32m   2446\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2447\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics:\n\u001b[0;32m-> 2448\u001b[0m     m\u001b[39m.\u001b[39;49mreset_state()\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/metrics/base_metric.py:259\u001b[0m, in \u001b[0;36mMetric.reset_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_states()\n\u001b[1;32m    258\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     backend\u001b[39m.\u001b[39;49mbatch_set_value([(v, \u001b[39m0\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m v \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariables])\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/backend.py:4312\u001b[0m, in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   4310\u001b[0m     \u001b[39mfor\u001b[39;00m x, value \u001b[39min\u001b[39;00m tuples:\n\u001b[1;32m   4311\u001b[0m         value \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(value, dtype\u001b[39m=\u001b[39mdtype_numpy(x))\n\u001b[0;32m-> 4312\u001b[0m         _assign_value_to_variable(x, value)\n\u001b[1;32m   4313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4314\u001b[0m     \u001b[39mwith\u001b[39;00m get_graph()\u001b[39m.\u001b[39mas_default():\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/keras/backend.py:4360\u001b[0m, in \u001b[0;36m_assign_value_to_variable\u001b[0;34m(variable, value)\u001b[0m\n\u001b[1;32m   4357\u001b[0m     variable\u001b[39m.\u001b[39massign(d_value)\n\u001b[1;32m   4358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4359\u001b[0m     \u001b[39m# For the normal tf.Variable assign\u001b[39;00m\n\u001b[0;32m-> 4360\u001b[0m     variable\u001b[39m.\u001b[39;49massign(value)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/tensorflow/python/ops/resource_variable_ops.py:990\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    988\u001b[0m   validate_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_shape \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shape\u001b[39m.\u001b[39mis_fully_defined()\n\u001b[1;32m    989\u001b[0m   kwargs[\u001b[39m\"\u001b[39m\u001b[39mvalidate_shape\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m validate_shape\n\u001b[0;32m--> 990\u001b[0m assign_op \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49massign_variable_op(\n\u001b[1;32m    991\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, value_tensor, name\u001b[39m=\u001b[39;49mname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    992\u001b[0m \u001b[39mif\u001b[39;00m read_value:\n\u001b[1;32m    993\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lazy_read(assign_op)\n",
      "File \u001b[0;32m~/projects/IISc/env/lib/python3.11/site-packages/tensorflow/python/ops/gen_resource_variable_ops.py:141\u001b[0m, in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m    140\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m    142\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mAssignVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, value, \u001b[39m\"\u001b[39;49m\u001b[39mvalidate_shape\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    143\u001b[0m       validate_shape)\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m    145\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuner_aa3.search(\n",
    "    X, Y, \n",
    "    epochs=40, \n",
    "    validation_data=(Xv, Yv), \n",
    "    batch_size=1, \n",
    "    use_multiprocessing=True, \n",
    "    callbacks=[stop_early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Phonon_to_Asthama_NN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 419, 512)          123392    \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 209, 512)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 209, 320)          1638720   \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 104, 320)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 33280)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 320)               10649920  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 321       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,412,353\n",
      "Trainable params: 12,412,353\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner_aa1.get_best_hyperparameters()[0]\n",
    "best_model = tuner_aa1.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(os.path.join('saved_models', 'supervised', 'aa_s1.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 0.0015 - binary_accuracy: 1.0000 - val_loss: 1.1550 - val_binary_accuracy: 0.6765\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 9.1159e-04 - binary_accuracy: 1.0000 - val_loss: 1.0122 - val_binary_accuracy: 0.5294\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 7.2297e-04 - binary_accuracy: 1.0000 - val_loss: 1.0854 - val_binary_accuracy: 0.6176\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 5.1406e-04 - binary_accuracy: 1.0000 - val_loss: 1.0958 - val_binary_accuracy: 0.6176\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 3.7769e-04 - binary_accuracy: 1.0000 - val_loss: 1.1410 - val_binary_accuracy: 0.6176\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 2.8416e-04 - binary_accuracy: 1.0000 - val_loss: 1.1459 - val_binary_accuracy: 0.6176\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 2.3978e-04 - binary_accuracy: 1.0000 - val_loss: 1.1489 - val_binary_accuracy: 0.6471\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 2.4403e-04 - binary_accuracy: 1.0000 - val_loss: 1.1907 - val_binary_accuracy: 0.6176\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 2.2192e-04 - binary_accuracy: 1.0000 - val_loss: 1.1757 - val_binary_accuracy: 0.6471\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 2.0004e-04 - binary_accuracy: 1.0000 - val_loss: 1.1925 - val_binary_accuracy: 0.6471\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 1.7946e-04 - binary_accuracy: 1.0000 - val_loss: 1.2196 - val_binary_accuracy: 0.6471\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 1.6336e-04 - binary_accuracy: 1.0000 - val_loss: 1.2253 - val_binary_accuracy: 0.6176\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 1.7779e-04 - binary_accuracy: 1.0000 - val_loss: 1.2702 - val_binary_accuracy: 0.6176\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 2s 168ms/step - loss: 1.3656e-04 - binary_accuracy: 1.0000 - val_loss: 1.2665 - val_binary_accuracy: 0.6471\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 1.2212e-04 - binary_accuracy: 1.0000 - val_loss: 1.2870 - val_binary_accuracy: 0.6471\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 1.0663e-04 - binary_accuracy: 1.0000 - val_loss: 1.2641 - val_binary_accuracy: 0.6176\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 2s 166ms/step - loss: 1.1367e-04 - binary_accuracy: 1.0000 - val_loss: 1.3339 - val_binary_accuracy: 0.6176\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 9.5299e-05 - binary_accuracy: 1.0000 - val_loss: 1.2660 - val_binary_accuracy: 0.5882\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 1.2548e-04 - binary_accuracy: 1.0000 - val_loss: 1.2943 - val_binary_accuracy: 0.6471\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 7.7303e-05 - binary_accuracy: 1.0000 - val_loss: 1.3203 - val_binary_accuracy: 0.6471\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 6.5246e-05 - binary_accuracy: 1.0000 - val_loss: 1.3141 - val_binary_accuracy: 0.6471\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 7.2798e-05 - binary_accuracy: 1.0000 - val_loss: 1.3451 - val_binary_accuracy: 0.6471\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 2s 164ms/step - loss: 7.3560e-05 - binary_accuracy: 1.0000 - val_loss: 1.3574 - val_binary_accuracy: 0.6471\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 6.0379e-05 - binary_accuracy: 1.0000 - val_loss: 1.3528 - val_binary_accuracy: 0.6471\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 2s 166ms/step - loss: 5.8642e-05 - binary_accuracy: 1.0000 - val_loss: 1.3511 - val_binary_accuracy: 0.6176\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 5.1491e-05 - binary_accuracy: 1.0000 - val_loss: 1.3778 - val_binary_accuracy: 0.6471\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 4.9253e-05 - binary_accuracy: 1.0000 - val_loss: 1.4027 - val_binary_accuracy: 0.6471\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 2s 165ms/step - loss: 4.3649e-05 - binary_accuracy: 1.0000 - val_loss: 1.4237 - val_binary_accuracy: 0.6471\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 4.3094e-05 - binary_accuracy: 1.0000 - val_loss: 1.4246 - val_binary_accuracy: 0.6176\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 3.6062e-05 - binary_accuracy: 1.0000 - val_loss: 1.4592 - val_binary_accuracy: 0.6471\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 2.7320e-05 - binary_accuracy: 1.0000 - val_loss: 1.4517 - val_binary_accuracy: 0.5882\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 2s 166ms/step - loss: 2.8396e-05 - binary_accuracy: 1.0000 - val_loss: 1.4823 - val_binary_accuracy: 0.6471\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 2.4000e-05 - binary_accuracy: 1.0000 - val_loss: 1.4827 - val_binary_accuracy: 0.6176\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 2.3882e-05 - binary_accuracy: 1.0000 - val_loss: 1.5118 - val_binary_accuracy: 0.6471\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 1.7233e-05 - binary_accuracy: 1.0000 - val_loss: 1.4918 - val_binary_accuracy: 0.5882\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 2.1377e-05 - binary_accuracy: 1.0000 - val_loss: 1.5167 - val_binary_accuracy: 0.5882\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 3s 168ms/step - loss: 1.4325e-05 - binary_accuracy: 1.0000 - val_loss: 1.5165 - val_binary_accuracy: 0.5882\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 1.7957e-05 - binary_accuracy: 1.0000 - val_loss: 1.5359 - val_binary_accuracy: 0.5882\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 1.8690e-05 - binary_accuracy: 1.0000 - val_loss: 1.5302 - val_binary_accuracy: 0.5882\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 3s 186ms/step - loss: 2.2323e-05 - binary_accuracy: 1.0000 - val_loss: 1.5538 - val_binary_accuracy: 0.5882\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 1.0046e-05 - binary_accuracy: 1.0000 - val_loss: 1.5918 - val_binary_accuracy: 0.6176\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 2.2549e-05 - binary_accuracy: 1.0000 - val_loss: 1.6249 - val_binary_accuracy: 0.6471\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 3s 179ms/step - loss: 1.3068e-05 - binary_accuracy: 1.0000 - val_loss: 1.5906 - val_binary_accuracy: 0.5882\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 3s 169ms/step - loss: 1.0921e-05 - binary_accuracy: 1.0000 - val_loss: 1.6115 - val_binary_accuracy: 0.5882\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 1.3532e-05 - binary_accuracy: 1.0000 - val_loss: 1.5942 - val_binary_accuracy: 0.5882\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 2s 162ms/step - loss: 1.7146e-05 - binary_accuracy: 1.0000 - val_loss: 1.6176 - val_binary_accuracy: 0.5882\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 1.3391e-05 - binary_accuracy: 1.0000 - val_loss: 1.6626 - val_binary_accuracy: 0.6471\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 1.0893e-05 - binary_accuracy: 1.0000 - val_loss: 1.6371 - val_binary_accuracy: 0.5882\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 1.1060e-05 - binary_accuracy: 1.0000 - val_loss: 1.6171 - val_binary_accuracy: 0.5882\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 9.9759e-06 - binary_accuracy: 1.0000 - val_loss: 1.6102 - val_binary_accuracy: 0.5882\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 2s 164ms/step - loss: 1.0795e-05 - binary_accuracy: 1.0000 - val_loss: 1.6295 - val_binary_accuracy: 0.5882\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 2s 161ms/step - loss: 8.3463e-06 - binary_accuracy: 1.0000 - val_loss: 1.6359 - val_binary_accuracy: 0.5882\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 3s 179ms/step - loss: 8.0883e-06 - binary_accuracy: 1.0000 - val_loss: 1.6479 - val_binary_accuracy: 0.5882\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 1.1030e-05 - binary_accuracy: 1.0000 - val_loss: 1.6442 - val_binary_accuracy: 0.5882\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 6.7913e-06 - binary_accuracy: 1.0000 - val_loss: 1.6414 - val_binary_accuracy: 0.5882\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 6.0785e-06 - binary_accuracy: 1.0000 - val_loss: 1.6461 - val_binary_accuracy: 0.5882\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 5.7839e-06 - binary_accuracy: 1.0000 - val_loss: 1.6812 - val_binary_accuracy: 0.5882\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 3s 185ms/step - loss: 1.1888e-05 - binary_accuracy: 1.0000 - val_loss: 1.6831 - val_binary_accuracy: 0.5882\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 5.8651e-06 - binary_accuracy: 1.0000 - val_loss: 1.6819 - val_binary_accuracy: 0.5882\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 5.4386e-06 - binary_accuracy: 1.0000 - val_loss: 1.6991 - val_binary_accuracy: 0.5882\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 5.3399e-06 - binary_accuracy: 1.0000 - val_loss: 1.7293 - val_binary_accuracy: 0.6176\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 6.8932e-06 - binary_accuracy: 1.0000 - val_loss: 1.7129 - val_binary_accuracy: 0.5882\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 3.2630e-06 - binary_accuracy: 1.0000 - val_loss: 1.7091 - val_binary_accuracy: 0.5882\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 6.1717e-06 - binary_accuracy: 1.0000 - val_loss: 1.7485 - val_binary_accuracy: 0.6176\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 7.7857e-06 - binary_accuracy: 1.0000 - val_loss: 1.7149 - val_binary_accuracy: 0.5882\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 1.2996e-05 - binary_accuracy: 1.0000 - val_loss: 1.6877 - val_binary_accuracy: 0.5294\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 4.2115e-06 - binary_accuracy: 1.0000 - val_loss: 1.6720 - val_binary_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 4.9680e-06 - binary_accuracy: 1.0000 - val_loss: 1.6850 - val_binary_accuracy: 0.5294\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 5.1599e-06 - binary_accuracy: 1.0000 - val_loss: 1.6990 - val_binary_accuracy: 0.5294\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 3.5068e-06 - binary_accuracy: 1.0000 - val_loss: 1.7192 - val_binary_accuracy: 0.5882\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 4.0005e-06 - binary_accuracy: 1.0000 - val_loss: 1.7255 - val_binary_accuracy: 0.5882\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 3s 179ms/step - loss: 5.3646e-06 - binary_accuracy: 1.0000 - val_loss: 1.7297 - val_binary_accuracy: 0.5882\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 6.0549e-06 - binary_accuracy: 1.0000 - val_loss: 1.7300 - val_binary_accuracy: 0.5882\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 3.9918e-06 - binary_accuracy: 1.0000 - val_loss: 1.7352 - val_binary_accuracy: 0.5882\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 3.7719e-06 - binary_accuracy: 1.0000 - val_loss: 1.7562 - val_binary_accuracy: 0.5882\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 2.8961e-06 - binary_accuracy: 1.0000 - val_loss: 1.7550 - val_binary_accuracy: 0.5882\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 5.5682e-06 - binary_accuracy: 1.0000 - val_loss: 1.7423 - val_binary_accuracy: 0.5588\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 3.8009e-06 - binary_accuracy: 1.0000 - val_loss: 1.7499 - val_binary_accuracy: 0.5882\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 7.1645e-06 - binary_accuracy: 1.0000 - val_loss: 1.7450 - val_binary_accuracy: 0.5294\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 4.4267e-06 - binary_accuracy: 1.0000 - val_loss: 1.7517 - val_binary_accuracy: 0.5294\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 2.4659e-06 - binary_accuracy: 1.0000 - val_loss: 1.7698 - val_binary_accuracy: 0.5882\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 3.6866e-06 - binary_accuracy: 1.0000 - val_loss: 1.7819 - val_binary_accuracy: 0.5882\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 4.0291e-06 - binary_accuracy: 1.0000 - val_loss: 1.7854 - val_binary_accuracy: 0.5882\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 3.0995e-06 - binary_accuracy: 1.0000 - val_loss: 1.7748 - val_binary_accuracy: 0.5294\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 3s 171ms/step - loss: 1.9150e-06 - binary_accuracy: 1.0000 - val_loss: 1.7812 - val_binary_accuracy: 0.5882\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 3s 175ms/step - loss: 3.8365e-06 - binary_accuracy: 1.0000 - val_loss: 1.7824 - val_binary_accuracy: 0.5588\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 3s 170ms/step - loss: 3.2184e-06 - binary_accuracy: 1.0000 - val_loss: 1.7843 - val_binary_accuracy: 0.5294\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 3s 173ms/step - loss: 1.1100e-05 - binary_accuracy: 1.0000 - val_loss: 1.7640 - val_binary_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 6.3460e-06 - binary_accuracy: 1.0000 - val_loss: 1.7598 - val_binary_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 3s 172ms/step - loss: 4.4756e-06 - binary_accuracy: 1.0000 - val_loss: 1.7677 - val_binary_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 8.1620e-06 - binary_accuracy: 1.0000 - val_loss: 1.7761 - val_binary_accuracy: 0.5294\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 2.8408e-06 - binary_accuracy: 1.0000 - val_loss: 1.7864 - val_binary_accuracy: 0.5294\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 3s 178ms/step - loss: 3.3480e-06 - binary_accuracy: 1.0000 - val_loss: 1.7952 - val_binary_accuracy: 0.5294\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 3s 181ms/step - loss: 7.2066e-06 - binary_accuracy: 1.0000 - val_loss: 1.7939 - val_binary_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 5.6045e-06 - binary_accuracy: 1.0000 - val_loss: 1.7957 - val_binary_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 3s 174ms/step - loss: 2.4100e-06 - binary_accuracy: 1.0000 - val_loss: 1.8024 - val_binary_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 2.6276e-06 - binary_accuracy: 1.0000 - val_loss: 1.8184 - val_binary_accuracy: 0.5294\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 3s 176ms/step - loss: 4.5872e-06 - binary_accuracy: 1.0000 - val_loss: 1.8168 - val_binary_accuracy: 0.5294\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 3.8039e-06 - binary_accuracy: 1.0000 - val_loss: 1.8137 - val_binary_accuracy: 0.5294\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 3s 179ms/step - loss: 5.5224e-06 - binary_accuracy: 1.0000 - val_loss: 1.8452 - val_binary_accuracy: 0.5882\n"
     ]
    }
   ],
   "source": [
    "model = best_model.fit(\n",
    "    X, Y,\n",
    "    epochs=100, \n",
    "    validation_data=(Xv, Yv), \n",
    "    batch_size=8, \n",
    "    use_multiprocessing=True, \n",
    "    # callbacks=[stop_early]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
