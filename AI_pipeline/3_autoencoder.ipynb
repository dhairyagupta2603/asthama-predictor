{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n",
      "2.12.0\n",
      "GPUs Available:  []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad\n",
    "from tensorflow.keras.metrics import Accuracy, BinaryAccuracy, CategoricalAccuracy, mean_squared_error\n",
    "from tensorflow.keras.layers import Conv2D, Conv1D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D, UpSampling1D, Softmax, MaxPool1D\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '1'\n",
    "tqdm.pandas()\n",
    "\n",
    "print(pd.__version__)\n",
    "print(tf.__version__)\n",
    "print(\"GPUs Available: \", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/mfcc_data/split_samples'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = save_path = os.path.join('..', '..', 'data', 'mfcc_data', 'split_samples')\n",
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'yy', 'ee', 'uu', 'oo']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonon_dirs = os.listdir(data_path)\n",
    "phonon_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading dataframes to environment: 100%|██████████| 5/5 [00:07<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "for _, phonon in tqdm(enumerate(phonon_dirs), total=5, desc='loading dataframes to environment'):\n",
    "    dfp = {}\n",
    "    dfp['train'] = pd.read_csv(os.path.join(data_path, phonon, 'train.csv'), sep=',', index_col=False)\n",
    "    dfp['val'] = pd.read_csv(os.path.join(data_path, phonon, 'validation.csv'), sep=',', index_col=False)\n",
    "    dfp['test'] = pd.read_csv(os.path.join(data_path, phonon, 'test.csv'), sep=',', index_col=False)\n",
    "    dfs[phonon] = dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dropping columns: 100%|██████████| 5/5 [00:00<00:00,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "def conv_to_32(df, cols): df[cols] = df[cols].astype(np.float32)\n",
    "\n",
    "for key, dfp in tqdm(dfs.items(), total=5, desc='dropping columns'):\n",
    "    for type_df, df in dfp.items():\n",
    "        df.drop(['per_frame_idx', 'mb_name', 'phonon'], axis=1, inplace=True)\n",
    "\n",
    "        # convert float64 to float32\n",
    "        conv_to_32(df, ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12'])\n",
    "\n",
    "        # convert catagory column to encoded\n",
    "        df['asthma_status'] = df['asthma_status'].astype('category')\n",
    "        df['asthma_status'] = df['asthma_status'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asthma_status\n",
       "0    326244\n",
       "1    204440\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['aa']['train']['asthma_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scaling and splitting: 100%|██████████| 5/5 [00:00<00:00,  8.68it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs_processed = {}\n",
    "for key, dfp in tqdm(dfs.items(), total=5, desc='scaling and splitting'):\n",
    "    dfp_processed = {}\n",
    "\n",
    "    for type_df, df in dfp.items():\n",
    "        dfp_processed[type_df] = {}\n",
    "        X = df.loc[:, df.columns != 'asthma_status'].to_numpy()\n",
    "        Y = df.loc[:, 'asthma_status'].to_numpy()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        dfp_processed[type_df]['x'] = X_scaled\n",
    "        dfp_processed[type_df]['y'] = Y\n",
    "    dfs_processed[key] = dfp_processed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder:\n",
    "    def __init__(self, input_dim):\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        self.encoder = self.make_encoder()\n",
    "        self.decoder = self.make_decoder()\n",
    "        self.autoencoder = keras.Sequential([self.encoder, self.decoder], name='Phonon_Autoencoder')\n",
    "\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    def make_encoder(self):\n",
    "        encoder = keras.Sequential([\n",
    "            Dense(32, activation='relu', input_shape=(self.input_dim,)),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(128, activation='relu')\n",
    "        ], name='phonon_encoder')\n",
    "        return encoder\n",
    "\n",
    "    \n",
    "    def make_decoder(self):\n",
    "        decoder = keras.Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(128,)),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(self.input_dim, activation='linear')\n",
    "        ], name='phonon_decoder')\n",
    "        return decoder\n",
    "\n",
    "ae = AutoEncoder(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder_Tuned:\n",
    "    def __init__(self, input_dim):\n",
    "        self.input_dim = input_dim        \n",
    "\n",
    "    def make_encoder(self, hp_layers, l1r, l2r):\n",
    "        encoder = keras.Sequential([\n",
    "            Dense(hp_layers[0], activation='relu', activity_regularizer=L1L2(l1=l1r, l2=l2r), input_shape=(self.input_dim,)),\n",
    "            Dropout(0.10),\n",
    "            Dense(hp_layers[1], activation='relu', activity_regularizer=L1L2(l1=l1r, l2=l2r))\n",
    "        ], name='phonon_encoder')\n",
    "        return encoder\n",
    "\n",
    "    \n",
    "    def make_decoder(self, hp_layers, l1r, l2r):\n",
    "        decoder = keras.Sequential([\n",
    "            Dense(hp_layers[1], activation='relu', activity_regularizer=L1L2(l1=l1r, l2=l2r), input_shape=(hp_layers[0],)),\n",
    "            Dropout(0.10),\n",
    "            Dense(hp_layers[2], activation='relu', activity_regularizer=L1L2(l1=l1r, l2=l2r)),\n",
    "            Dropout(0.10),\n",
    "            Dense(self.input_dim, activation='linear')\n",
    "        ], name='phonon_decoder')\n",
    "        return decoder\n",
    "    \n",
    "    def make_model(self, hp):\n",
    "        l1r, l2r = 0.005, 0.005\n",
    "        hpl0 = hp.Int('layer0', min_value=64, max_value=512, step=64)\n",
    "        hpl1 = hp.Int('layer1', min_value=64, max_value=512, step=64)\n",
    "        hpl2 = hp.Int('layer2', min_value=64, max_value=512, step=64)\n",
    "        hpl3 = hp.Int('layer3', min_value=64, max_value=512, step=64)\n",
    "\n",
    "        self.encoder = self.make_encoder((hpl0, hpl1), l1r, l2r)\n",
    "        self.decoder = self.make_decoder((hpl1, hpl2, hpl3), l1r, l2r)\n",
    "\n",
    "        autoencoder = keras.Sequential([self.encoder, self.decoder], name='Phonon_Autoencoder')\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "        return autoencoder\n",
    "\n",
    "\n",
    "aet = AutoEncoder_Tuned(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_tuner1 = kt.Hyperband(\n",
    "    aet.make_model,\n",
    "    objective='val_loss',\n",
    "    max_epochs=15,\n",
    "    factor=3,\n",
    "    directory='tuned_models',\n",
    "    project_name='aa_us'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aa = dfs_processed['aa']['train']\n",
    "val_aa = dfs_processed['aa']['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 27s]\n",
      "val_loss: 0.34715625643730164\n",
      "\n",
      "Best val_loss So Far: 0.29748964309692383\n",
      "Total elapsed time: 00h 41m 21s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "# tb_storage = keras.callbacks.TensorBoard(\"/tmp/tb_logs\")\n",
    "ae_tuner1.search(\n",
    "    train_aa['x'], train_aa['y'], \n",
    "    epochs=30, \n",
    "    validation_data=(val_aa['x'], val_aa['y']), \n",
    "    batch_size=128, \n",
    "    use_multiprocessing=True, \n",
    "    callbacks=[stop_early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_hist = ae.autoencoder.history.history\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(metric_hist['loss'])\n",
    "plt.plot(metric_hist['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstructionScore(originalDF, reducedDF):\n",
    "    loss = np.sum((np.array(originalDF) - np.array(reducedDF))**2, axis=0)\n",
    "    # loss = pd.Series(data=loss,index=originalDF.index)\n",
    "    loss = (loss-np.min(loss))/(np.max(loss)-np.min(loss))\n",
    "    print('Mean for reconstruction scores: ', np.mean(loss))\n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
